## Практическое задание

1. Подберите скорость обучения (alpha) и количество итераций для градиентного спуска.

2. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее:

```python
for i in range(1000):
    y_pred = np.dot(W, X)
    err = calc_mse(y, y_pred)
    # for ii in range(W.shape[0]):
    #     W[ii] -= alpha * (1/n * 2 * np.sum(X[ii] * (y_pred - y)))
    W -= (alpha * (1/n * 2 * np.sum(X * (y_pred - y))))
    if i % 100 == 0:
        print(i, W, err)
```

## Решение

### Задача 1

- Модуль `linear_model.py` содержит реализацию модели градиентного спуска
c использованием `numpy`.
- Скрипт `example_1.py` генерирует датасет с помощью `sklearn.datasets` и
проводит обучение модели на разных скоростях,
сохраняя результаты в файлы `example_1_log_{:02d}.csv`.
Параметры датасета и модели хранятся в файле `example_1_par.json`.
- В ноутбуке `example_1.ipynb` средствами `pandas` и `matplotlib.pyplot`
для каждой скорости обучения генерируют графики зависимости
функционала ошибки и отклонения вектора весов от номера итерации.  
- Для данного датасета лучший результат достигается при скорости 0.25:
за 1e5 итераций невязка падает до 1e6.

### Задача 2

Нужно умножить транспонированную матрицу `X` на вектор `y_pred - y`
с помощью `numpy.dot`:

```python
W -= 2 * alpha * np.dot(X.T, y_pred - y) / n
```
